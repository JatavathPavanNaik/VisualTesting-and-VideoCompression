{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def group_contours(contours, horizontal_proximity=30, vertical_proximity=30):\n",
    "    # Defines a function to determine if two contours are close to each other\n",
    "    def are_close(c1, c2):\n",
    "        x1, y1, w1, h1 = cv2.boundingRect(c1)\n",
    "        x2, y2, w2, h2 = cv2.boundingRect(c2)\n",
    "\n",
    "        # Check horizontal closeness\n",
    "        horizontal_close = (x2 <= x1 + w1 + horizontal_proximity) and (x1 <= x2 + w2 + horizontal_proximity)\n",
    "\n",
    "        # Check vertical closeness\n",
    "        vertical_close = (y2 <= y1 + h1 + vertical_proximity) and (y1 <= y2 + h2 + vertical_proximity)\n",
    "\n",
    "        return horizontal_close and vertical_close\n",
    "\n",
    "    groups = []\n",
    "    used = set()\n",
    "\n",
    "    # Iteratively group close contours\n",
    "    for i in range(len(contours)):\n",
    "        if i in used:\n",
    "            continue\n",
    "        group = [contours[i]]\n",
    "        queue = [i]\n",
    "        used.add(i)\n",
    "        while queue:\n",
    "            idx = queue.pop(0)\n",
    "            for j in range(len(contours)):\n",
    "                if j not in used and are_close(contours[idx], contours[j]):\n",
    "                    used.add(j)\n",
    "                    queue.append(j)\n",
    "                    group.append(contours[j])\n",
    "        groups.append(group)\n",
    "    return groups\n",
    "\n",
    "def draw_bounding_boxes_on_changes_and_save(image_path1, image_path2, save_path):\n",
    "    # Load images\n",
    "    img1 = cv2.imread(image_path1)\n",
    "    img2 = cv2.imread(image_path2)\n",
    "\n",
    "    if img1 is None or img2 is None:\n",
    "        raise FileNotFoundError(\"One or both images could not be loaded.\")\n",
    "\n",
    "    # Ensure images are the same size\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(\"Images must have the same dimensions.\")\n",
    "\n",
    "    # Convert images to grayscale\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the difference and apply threshold\n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours from the thresholded image\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter out very small contours\n",
    "    filtered_contours = [c for c in contours if cv2.contourArea(c) > 0]\n",
    "    contour_groups = group_contours(filtered_contours)\n",
    "\n",
    "    # Draw bounding boxes around contour groups\n",
    "    for group in contour_groups:\n",
    "        all_points = np.vstack([cv2.boxPoints(cv2.minAreaRect(contour)) for contour in group])\n",
    "        x, y, w, h = cv2.boundingRect(all_points)\n",
    "        cv2.rectangle(img2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save and display the processed image\n",
    "    cv2.imwrite(save_path, img2)\n",
    "\n",
    "    img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img2_rgb)\n",
    "    plt.title('Second Image with Bounding Boxes')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "draw_bounding_boxes_on_changes_and_save('with_element.png', 'with_out_symbol.png', 'processed_image.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_stagnant_frames(video_path, output_path, change_threshold=30, area_threshold=100):\n",
    "    # Setup video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise FileNotFoundError(\"Video file could not be opened.\")\n",
    "\n",
    "    # Obtain input video frame rate and resolution\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Setup video writer with the same frame rate as the input video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID'\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    " \n",
    "    # Read the first frame\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        raise ValueError(\"Cannot read video file.\")\n",
    "    \n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        # Read next frame\n",
    "        ret, frame2 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate the absolute difference and threshold\n",
    "        diff = cv2.absdiff(gray1, gray2)\n",
    "        _, thresh = cv2.threshold(diff, change_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        significant_change = any(cv2.contourArea(contour) > area_threshold for contour in contours)\n",
    "\n",
    "        if significant_change:\n",
    "            out.write(frame2)\n",
    "            gray1 = gray2  # Update the reference frame to the current frame\n",
    "\n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Processing complete. Output saved to:\", output_path)\n",
    "\n",
    "# Example usage\n",
    "remove_stagnant_frames('/Users/jatavathpavannaik/Documents/ICodeTest/Screen Recording 2024-05-19 at 5.25.28 PM.mov', 'output_video.mp4')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer-Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
